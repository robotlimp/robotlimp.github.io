<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Verifiably Following Complex Robot Instructions with Foundation Models.">
  <meta name="keywords" content="Limp, Robotlimp, Foundation models">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Verifiably Following Complex Robot Instructions with Foundation Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>
  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
  </nav>

  <section class="hero">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Verifiably Following Complex Robot Instructions with Foundation
              Models</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <!-- Author Names Omitted for Anonymous Review -->
                Supplementary Videos and Demonstrations
              </span>
              <span class="author-block">
            </div>
          </div>
        </div>
  </section>

  <!-- 
  <section class="section" style="margin-top: -5%">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div class="columns is-centered has-text-centered">
          <h2 class="title is-3">Abstract</h2>
        </div>
        <p class="subtitle has-text-justified" style="font-size: 14px; padding-top: 1%;">
          Enabling robots to follow complex natural language instructions is an important yet challenging problem.
          People want to flexibly express constraints, refer to arbitrary landmarks and verify behavior when instructing
          robots.
          Conversely, robots must disambiguate human instructions into specifications and ground instruction referents
          in the real world.
          We propose Language Instruction grounding for Motion Planning (LIMP), a system that leverages foundation
          models and temporal logics
          to generate instruction-conditioned semantic maps that enable robots to verifiably follow expressive and
          long-horizon instructions
          with open vocabulary referents and complex spatiotemporal constraints. In contrast to prior methods for using
          foundation models in robot
          task execution, LIMP constructs an explainable instruction representation that reveals the robot's alignment
          with an instructor's intended motives
          and affords the synthesis of robot behaviors that are correct-by-construction. We demonstrate LIMP in three
          real-world environments,
          across a set of 35 complex spatiotemporal instructions, showing the generality of our approach and the ease of
          deployment in novel
          unstructured domains. In our experiments, LIMP can spatially ground open-vocabulary referents and synthesize
          constraint-satisfying
          plans in 90% of object-goal navigation and 71% of mobile manipulation instructions.
        </p>
      </div>
    </div>
  </section> -->


  <section style="margin-top: -3%">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <img id="teaser" src="./static/images/limp_splash.jpg" alt="Limp teaser image." class="teaser-image"
          height="100%" />

        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-steve">
            <video poster="" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/nav.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-shiba">
            <video poster="" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/pick.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-fullbody">
            <video poster="" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/place.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-blueshirt">
            <video poster="" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/full.mp4" type="video/mp4">
            </video>
          </div>
        </div>
        <h2 class="subtitle has-text-justified" style="font-size: 14px; padding-top: 1%;">
          <!-- Language Instruction grounding for Motion Planning (LIMP) executing the instruction.  -->
          This figure visualizes our approach, Language Instruction grounding for Motion Planning (LIMP), executing the
          instruction: "<span style="font-style: italic;">Bring the green plush toy to the whiteboard in front of it,
            watch out for the
            robot in front of the toy</span>".
          LIMP has no semantic information of the environment prior to this instruction, rather at runtime, our approach
          leverages VLMs and spatial reasoning to detect and ground open-vocabulary instruction referents. LIMP then
          generates a verifiably correct task and motion plan that enables the robot to navigate from its start
          location <span style="color: goldenrod;">(yellow, A)</span>, to the green plush toy <span
            style="color: green;">(green, B)</span>, execute a pick skill which searches for and grasps
          the object, then navigate to the whiteboard <span style="color: blue;">(blue, C)</span> while avoiding the
          robot in the space <span style="color: red;">(red circles)</span>, to finally execute a place skill which sets
          the object down.
        </h2>
      </div>

    </div>
  </section>

  <div class="container">
    <div class="container is-max-desktop">
      <div class="column has-text-centered">
        <p class="title is-3">Real-World Demonstration<br><span class="title is-5">(All robot videos are 1x
            speed)</span></p>
        <p class="subtitle has-text-justified" style="font-size: 14px; padding-top:1%">
          Below are additional real world examples of LIMP generating task and motion plans to follow expressive
          instructions with complex spatiotemporal constraints.
          Each demonstration has two videos, the top video visualizes instruction translation, referent grounding,
          task progression semantic maps and computed motion plans for each example. The bottom video
          shows a robot executing the generated plan in the real world. Please see our paper for more details on our
          approach.
        </p>
      </div>
    </div>
    <br>

    <div class="columns is-centered">
      <div class="column has-text-centered">
        <div class="content">
          <h3 class="title is-5">Demo 1</h3>
          <!-- <video id="replay-video" controls muted preload loop playsinline width="100%">
            <source src="./static/videos/demo1_info.mp4" type="video/mp4">
          </video> -->
          <div class="publication-video">
            <iframe src="https://drive.google.com/file/d/1QLxN8P_aOznVyFZtBmpuHv5XCj2-kghS/preview" frameborder="0"
              allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
        <div class="content has-text-centered">
          <div class="publication-video">
            <video id="replay-video" controls muted preload loop playsinline width="100%">
              <source src="./static/videos/demo1.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>


      <div class="column has-text-centered">
        <div class="content">
          <h3 class="title is-5">Demo 2</h3>
          <!-- <video id="replay-video" controls muted preload loop playsinline width="100%">
            <source src="./static/videos/demo2_info.mp4" type="video/mp4">
          </video> -->
          <div class="publication-video">
            <iframe src="https://drive.google.com/file/d/1nsySPHRg1qYTNoJ4IqEJTbxndqa4T5By/preview" frameborder="0"
              allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
        <div class="content has-text-centered">
          <div class="publication-video">
            <video id="replay-video" controls muted preload loop playsinline width="100%">
              <source src="./static/videos/demo2.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>

      <div class="column has-text-centered">
        <div class="content">
          <h3 class="title is-5">Demo 3</h3>
          <!-- <video id="replay-video" controls muted preload loop playsinline width="100%">
            <source src="./static/videos/demo3_info.mp4" type="video/mp4">
          </video> -->
          <div class="publication-video">
            <iframe src="https://drive.google.com/file/d/1Pn81r4SPOu2V4_DBoIEhSg6G34iEUGds/preview" frameborder="0"
              allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
        <div class="content has-text-centered">
          <div class="publication-video">
            <video id="replay-video" controls muted preload loop playsinline width="100%">
              <source src="./static/videos/demo3.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="container" style="padding-top: 3%;">
    <div class="container is-max-desktop">
      <div class="column has-text-centered">
        <p class="title is-3">Baseline Comparison<br><span class="title is-5">(All robot videos are 1x
            speed)</span></p>
        <p class="subtitle has-text-justified" style="font-size: 14px; padding-top:1%">
          We compare LIMP with baseline implementations of an LLM planner (NLmap-Saycan) and an LLM code-writing planner (Code-as-policies), representing
          state-of-the-art approaches for language-conditioned robot instruction following. To ensure competitive
          performance, we integrate our spatial grounding module and low-level robot control into these baselines, allowing them to query our module for 3D object positions, execute
          manipulation options, and use our path planner. We observe that LLM and code-writing planners are quite adept at generating
          sequential subgoals, but struggle with temporal constraint adherence. In contrast, our approach ensures each robot step adheres to constraints while achieving subgoals, as illustrated in the example below. 
        </p>

        <p><span style="font-size: 14px; font-weight: bold; text-decoration: underline;">Instruction</span><br><span>"Hey, I want you to bring the plush toy on the table to the tree, </span> <span style="color: red;">make sure to avoid the trash bin when bringing the toy"</span></p>
        <br>
      </div>
    </div>


    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h3 class="title is-5">LIMP (Ours)</h3>
        <div class="content has-text-centered">
          <div class="publication-video">
            <video id="replay-video" controls muted preload loop playsinline width="100%">
              <source src="./static/videos/baselines/toy_tree_limp_planner.mov" type="video/mp4">
            </video>
          </div>
        </div>
      </div>


      <div class="column has-text-centered">
        <div class="content has-text-centered">
          <h3 class="title is-5">NLMap-Saycan</h3>
          <div class="publication-video">
            <video id="replay-video" controls muted preload loop playsinline width="100%">
              <source src="./static/videos/baselines/toy_tree_LLM_Planner.mov" type="video/mp4">
            </video>
          </div>
        </div>
      </div>

      <div class="column has-text-centered">
        <div class="content has-text-centered">
          <h3 class="title is-5">Code-as-policies</h3>
          <div class="publication-video">
            <video id="replay-video" controls muted preload loop playsinline width="100%">
              <source src="./static/videos/baselines/toy_tree_codegen_planner.mov" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </div>



  <br>
  <br>

  <script>
    function loadVideo() {
      var videoSelector = document.getElementById('videoSelector');
      var videoPlayer = document.getElementById('videoPlayer');
      var videoSource = document.getElementById('videoSource');

      var selectedVideo = videoSelector.value;
      videoSource.src = selectedVideo;
      videoPlayer.load();
    }
  </script>
</body>

</html>